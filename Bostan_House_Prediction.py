# -*- coding: utf-8 -*-
"""Training_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iuj7blpn6DOEvyXvTojfFosUnAoUV877
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.datasets import load_boston
from sklearn import preprocessing
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from IPython.display import HTML

boston = load_boston()
print(boston.DESCR)     #description of the dataset

features = pd.DataFrame(boston.data,columns=boston.feature_names)
features

#preprocessing features  scaling of features
standardscaler = preprocessing.StandardScaler()
features_scaled=standardscaler.fit_transform(features)
features_scaled

target = pd.DataFrame(boston.target,columns=['target'])
target

#concatinating features and target into dataframe, setting axis=1 concatinating column wise
df = pd.concat([features,target],axis=1)
df

"""**Visualization**"""

#setting precision to 2 place decimal value using round
df.describe().round(decimals=2)

#calculating correlation between every column on the date
corr = df.corr('pearson')
corrs = [abs(corr[attr]['target'])for attr in list(features)]  #taking absolute value of correlation
l = list(zip(corrs,list(features))) #making list of pair (corrs,features)
l.sort(key=lambda x:x[0],reverse=True)
corrs,labels = list(zip((*l))) #unzipping pair to two list

#plot correlation wrt target value as bar graph
index = np.arange(len(labels))
plt.figure(figsize=(10,5))
plt.bar(index,corrs,width=0.7)
plt.xlabel('attributes')
plt.ylabel('correlation with target value')
plt.xticks(index,labels)
plt.show()

"""Normalization"""

X =df['LSTAT'].values
Y =df['target'].values
#before normalization
Y[:5]

x_scaler = MinMaxScaler()
X = x_scaler.fit_transform(X.reshape(-1,1))
X = X[:,-1]
y_scaler=MinMaxScaler()
Y=y_scaler.fit_transform(Y.reshape(-1,1))
Y=Y[:,-1]

#after normalization
Y[:5]

"""Splitting the data"""

#splitting the data into 80%train data 20% test data
xtrain,xtest,ytrain,ytest =train_test_split(X,Y,test_size=0.2)
xtrain=xtrain.reshape(-1,1)
ytrain=ytrain.reshape(-1,1)
xtest=xtest.reshape(-1,1)
ytest=ytest.reshape(-1,1)

"""Training the model"""

lm = LinearRegression()  #define regression object

lm.fit(xtrain,ytrain)   #fitting the model

lm.coef_      #parameter of feature

"""Making Prediction"""

predictions = lm.predict(xtest)   #making prediction

#plotting
plt.scatter(ytest,predictions)
plt.xlabel('Y Test')
plt.ylabel('Prediction')

#import evaluation metrices
from sklearn import metrics
print('MSE: ',metrics.mean_squared_error(ytest,predictions))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(ytest,predictions)))

p = pd.DataFrame(list(zip(xtest,ytest,predictions)),columns=['x','target_y','prediction'])
p

"""Plotting the predict vlaues against the target values"""

plt.scatter(xtest,ytest,color='b')
plt.plot(xtest,predictions,color='r')

#reshaping to change the shape required by scaler
prediction =predictions.reshape(-1,1)
xtest=xtest.reshape(-1,1)
ytest=ytest.reshape(-1,1)
xtest_scaled=x_scaler.inverse_transform(xtest)
ytest_scaled=y_scaler.inverse_transform(ytest)
predictions_scaled=y_scaler.inverse_transform(predictions)

#to remove extra dim
xtest_scaled=xtest_scaled[:,-1]
ytest_scaled=ytest_scaled[:,-1]
predictions_scaled=predictions_scaled[:,-1]

p=pd.DataFrame(list(zip(xtest_scaled,ytest_scaled,predictions_scaled)),columns=['x','target_y','prediction'])
p=p.round(decimals=2)
p

